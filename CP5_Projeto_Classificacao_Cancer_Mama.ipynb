{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7bd616",
   "metadata": {},
   "source": [
    "\n",
    "# CP5 – Modelo de Classificação com IA (Classificação de Câncer de Mama - UCI/Scikit-Learn)\n",
    "\n",
    "**Aluno:** _Preencha com seu nome_  \n",
    "**Disciplina:** Inteligência Artificial / Machine Learning  \n",
    "**Entrega:** Projeto individual – Classificação supervisionada  \n",
    "\n",
    "---\n",
    "\n",
    "## Definição do Problema\n",
    "\n",
    "### Objetivo\n",
    "Classificar tumores de mama como **Malignos** ou **Benignos** a partir de medidas reais obtidas de imagens (features numéricas), caracterizando um **problema de classificação binária**.\n",
    "\n",
    "### Justificativa\n",
    "Câncer de mama é um problema de grande impacto em saúde pública. Modelos de classificação podem **auxiliar no apoio à decisão clínica**, priorizando exames e encaminhando pacientes para investigação adicional. O dataset escolhido é amplamente utilizado como benchmark em ML, com qualidade e documentação reconhecidas, o que facilita a **reprodutibilidade** e a **clareza metodológica**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23628be",
   "metadata": {},
   "source": [
    "\n",
    "## Descrição do Dataset\n",
    "\n",
    "- **Nome:** Breast Cancer Wisconsin (Diagnostic)  \n",
    "- **Origem/Fonte:** UCI Machine Learning Repository (via scikit-learn)  \n",
    "- **Link (referência):** https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+original  \n",
    "- **Acesso:** via `sklearn.datasets.load_breast_cancer()`  \n",
    "\n",
    "**Observação:** a versão disponibilizada pelo `scikit-learn` é a **Breast Cancer Wisconsin (Diagnostic)**.  \n",
    "Contém **569 amostras** e **30 variáveis explicativas** (todas numéricas), mais a **variável-alvo** binária: 0 (maligno) e 1 (benigno).\n",
    "\n",
    "As features incluem estatísticas (média, erro padrão, pior valor) de medidas como:\n",
    "- raio, textura, perímetro, área, suavidade, compacidade, concavidade, número de pontos côncavos, simetria, dimensão fractal.\n",
    "\n",
    "Este dataset **não contém dados sensíveis identificáveis** e é amplamente usado para ensino e pesquisa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Imports principais ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Para evitar warnings excessivos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc998",
   "metadata": {},
   "source": [
    "## Carregamento e Exploração Inicial (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90accf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carrega dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "# Informações básicas\n",
    "n_rows, n_cols = X.shape\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(f\"Linhas: {n_rows}, Colunas (features): {n_cols}\")\n",
    "print(\"Alvo (0=Maligno, 1=Benigno):\", dict(zip(classes, counts)))\n",
    "\n",
    "# Visualiza primeiras linhas\n",
    "display(X.head())\n",
    "\n",
    "# Verifica valores ausentes\n",
    "missing = X.isnull().sum().sum()\n",
    "print(f\"Valores ausentes totais nas features: {missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5ce56",
   "metadata": {},
   "source": [
    "### Checagem simples de outliers (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checagem simples via z-score (não vamos remover, apenas reportar)\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = np.abs(zscore(X))\n",
    "# Considera como \"outlier\" se z-score > 3 em qualquer feature (contagem por linha)\n",
    "outlier_flags = (z_scores > 3).any(axis=1)\n",
    "print(f\"Amostras com algum z-score > 3: {outlier_flags.sum()} de {len(outlier_flags)} ({outlier_flags.mean()*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daacc54",
   "metadata": {},
   "source": [
    "## Divisão de Dados (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Tamanhos -> X_train:\", X_train.shape, \"| X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd96846",
   "metadata": {},
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4fa5bf",
   "metadata": {},
   "source": [
    "\n",
    "Modelos testados (mínimo 3 exigidos pela atividade):\n",
    "\n",
    "- **Regressão Logística** (com padronização)\n",
    "- **LDA – Linear Discriminant Analysis** (com padronização)\n",
    "- **RandomForest** (árvore de decisão em conjunto; não requer padronização)\n",
    "- **KNN – k-vizinhos** (com padronização)\n",
    "\n",
    "> Observação: usamos `Pipeline` para garantir que o `StandardScaler` seja aplicado **apenas** aos dados de treino dentro do fluxo de validação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500, random_state=42))\n",
    "    ]),\n",
    "    \"LDA\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LinearDiscriminantAnalysis())\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=300, random_state=42))\n",
    "    ]),\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier(n_neighbors=7))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "def evaluate_model(pipe, X_train, y_train, X_test, y_test):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds)\n",
    "    rec = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    report = classification_report(y_test, preds, target_names=[\"Maligno (0)\", \"Benigno (1)\"])\n",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm, \"report\": report, \"model\": pipe}\n",
    "\n",
    "results = {}\n",
    "for name, pipe in models.items():\n",
    "    results[name] = evaluate_model(pipe, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Tabela de métricas\n",
    "metrics_df = pd.DataFrame({\n",
    "    model: { \n",
    "        \"Acurácia\": res[\"acc\"],\n",
    "        \"Precisão\": res[\"prec\"],\n",
    "        \"Recall\": res[\"rec\"],\n",
    "        \"F1-Score\": res[\"f1\"]\n",
    "    }\n",
    "    for model, res in results.items()\n",
    "}).T.sort_values(\"F1-Score\", ascending=False)\n",
    "\n",
    "display(metrics_df.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5f135",
   "metadata": {},
   "source": [
    "### Matrizes de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, res in results.items():\n",
    "    cm = res[\"cm\"]\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(f\"Matriz de Confusão - {name}\")\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(2)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(['Maligno (0)', 'Benigno (1)'])\n",
    "    ax.set_yticklabels(['Maligno (0)', 'Benigno (1)'])\n",
    "    ax.set_ylabel('Verdadeiro')\n",
    "    ax.set_xlabel('Predito')\n",
    "\n",
    "    # Anotações\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd0ca2",
   "metadata": {},
   "source": [
    "### Relatórios de Classificação (por modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f657f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(res[\"report\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20543f0",
   "metadata": {},
   "source": [
    "### Correlação entre features (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = X.corr()\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(corr.values, aspect='auto')\n",
    "ax.set_title(\"Mapa de Correlação (features)\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "# Para não poluir, omitimos todos os rótulos (são 30). Em relatórios, recomenda-se salvar com alta resolução.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77dbb38",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretação dos Resultados\n",
    "\n",
    "- A tabela de métricas apresenta uma **comparação direta** entre os modelos.  \n",
    "- O critério principal adotado aqui é o **F1-Score**, por equilibrar Precisão e Recall em um problema de saúde (reduz falsos negativos).  \n",
    "- Em geral, modelos lineares como **LDA** e **Regressão Logística** costumam performar muito bem neste dataset por conta de sua separabilidade. **RandomForest** também tende a obter alto desempenho sem grande ajuste fino.\n",
    "\n",
    "> **Modelo recomendado:** selecionar o **maior F1-Score** observado na sua execução (consulte a tabela exibida) e justificá-lo com base no equilíbrio entre Precisão e Recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794deac",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusão\n",
    "\n",
    "**Principais aprendizados:**\n",
    "- A importância do **pré-processamento** (padronização) para modelos sensíveis à escala (LR, LDA, KNN).\n",
    "- Avaliar com múltiplas métricas (**Acurácia, Precisão, Recall, F1**) dá uma visão mais robusta que uma métrica isolada.\n",
    "- O dataset demonstra que **modelos lineares** podem ser muito competitivos quando as classes são bem separáveis.\n",
    "\n",
    "**Melhorias futuras:**\n",
    "- **Validação cruzada** e **ajuste de hiperparâmetros** (GridSearchCV/RandomizedSearchCV).\n",
    "- Seleção/engenharia de features e análise de **importância de variáveis** (ex.: `coef_` da LR/LDA, `feature_importances_` da RandomForest).\n",
    "- Análise de **curvas ROC/PR** com thresholds para balancear melhor Precisão vs. Recall conforme o objetivo clínico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a13a0a",
   "metadata": {},
   "source": [
    "\n",
    "## Reprodutibilidade\n",
    "\n",
    "- `random_state=42` onde aplicável (treino/teste e alguns modelos).  \n",
    "- Ambiente recomendado: **Google Colab** ou **Jupyter Notebook** com Python 3.10+ e scikit-learn 1.3+.  \n",
    "- Bibliotecas utilizadas: `pandas`, `numpy`, `scikit-learn`, `matplotlib`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b0d6f",
   "metadata": {},
   "source": [
    "\n",
    "## Como Executar (Google Colab)\n",
    "\n",
    "1. Faça upload deste arquivo `.ipynb` para o Google Drive e **abra com o Colab**.  \n",
    "2. Execute as células **de cima para baixo**.  \n",
    "3. Ao final, confira a **tabela de métricas** e justifique o **modelo final** com base nas métricas (especialmente F1-Score).\n",
    "\n",
    "## Entregáveis Recomendados\n",
    "\n",
    "- Repositório no GitHub contendo:\n",
    "  - Este notebook (`.ipynb`)\n",
    "  - Um `README.md` com descrição do problema, passos para execução e principais resultados\n",
    "  - (Opcional) Imagens geradas (matrizes de confusão) caso deseje salvar figuras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff382410",
   "metadata": {},
   "source": [
    "\n",
    "## Apêndice – Atendendo à Rubrica\n",
    "\n",
    "- **Escolha do problema e dataset:** problema real e relevante (diagnóstico auxiliar), dataset público e confiável (UCI).  \n",
    "- **Organização e clareza do código:** células separadas por etapa, comentários e prints claros.  \n",
    "- **Pré-processamento:** verificação de ausentes, checagem simples de outliers, padronização em pipelines.  \n",
    "- **Modelagem:** 4 modelos (≥3 exigidos) com `train_test_split`.  \n",
    "- **Métricas:** acurácia, precisão, recall, F1 e matrizes de confusão.  \n",
    "- **Conclusões e análise crítica:** interpretação comparativa e melhorias futuras.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
